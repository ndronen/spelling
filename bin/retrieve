#!/usr/bin/env python

import sys
import argparse
import pandas as pd

from sklearn.neighbors import NearestNeighbors

import spelling.dictionary as dictionary
import spelling.features
from spelling.utils import build_progressbar

#data_dir = '../modeling/data/spelling/experimental/'
#data_path = 'non-word-error-detection-experiment-04-generated-negative-examples.csv'

def build_retriever(name, vocabulary):
    # The nearest-neighbors and Aspell retrievers are quite slow compared
    # to their edit distance and hash bucket counterparts.
    if retriever == 'aspell':
        return dictionary.AspellRetriever(vocabulary)
    elif retriever == 'editdistance':
        return dictionary.EditDistanceRetriver(vocabulary)
    elif retriever == 'hashbucket':
        return dictionary.HashBucketRetriever(
            vocabulary, spelling.features.metaphone)
    elif retriever == 'neighbor':
        estimator = NearestNeighbors(n_neighbors=10, metric='hamming',
                algorithm='auto')
        return dictionary.NearestNeighborsRetriever(vocabulary, estimator)
    else:
        raise ValueError('unknown retriever %s' % retriever)

def main(args):
    error_df = pd.read_csv(args.csv_path, sep='\t', encoding='utf8')
    vocab_df = pd.read_csv(args.vocabulary_path, sep='\t', encoding='utf8')

    start = args.start
    end = len(error_df) if args.end == -1 else args.end
    non_words = error_df.word.tolist()[start:end]

    vocabulary = vocab_df[args.vocab_colname].unique()
    retriever = build_retriever(args.retriever, vocabulary)

    suggestions = {}
    pbar = build_progressbar(non_words)
    for i,non_word in enumerate(non_words):
        pbar.update(i+1)
        suggestions[non_word] = retriever[non_word]

def build_parser():
    parser = argparse.ArgumentParser(
        description='retrieve a list of candidate replacements for a spelling error')
    parser.add_argument(
        'retriever', metavar='RETRIEVER',
        choices=['aspell', 'editdistance', 'hashbucket', 'neighbors'],
        help='the name of the retriever')
    parser.add_argument(
        'csv_path', metavar='CSV_PATH', type=str,
        help='path to CSV file with a column containing errors')
    parser.add_argument(
        'vocabulary_path', metavar='VOCABULARY_PATH', type=str,
        help='path to a CSV file with a column containing the vocabulary')
    parser.add_argument(
        '--error-colname', type=str, default="word",
        help='name of the error column in the error CSV (default="word")')
    parser.add_argument(
        '--vocab-colname', type=str, default="word",
        help='name of the word column in the vocabulary CSV (default="word")')
    parser.add_argument(
        '--start-index', type=int, default=0, help='ignore errors before this index (default=0)')
    parser.add_argument(
        '--end-index', type=int, default=-1, help='ignore errors after this index (default=-1)')

    return parser.parse_args()

if __name__ == '__main__':
    sys.exit(main(build_parser()))
