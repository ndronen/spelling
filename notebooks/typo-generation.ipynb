{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import enchant\n",
    "import textblob\n",
    "from textblob import TextBlob\n",
    "from langdetect import detect\n",
    "import collections\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "babyname_fn = \"data/babynames.csv\"\n",
    "small_text_fn = 'data/responseText-0.txt'\n",
    "text_fn = \"data/responseText-500k.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['darryle', 'fawn', 'evalyn', 'sonji', 'darryll', 'sonja', 'elvina', 'suzann', 'timmothy', 'elva', 'woody', 'gabriella', 'gabrielle', 'cherrie', 'karlee', 'roena', 'lori', 'hermann', 'lora', 'karley', 'callie', 'dell', 'elihu', 'yulissa', 'errol', 'caryl', 'caryn', 'arminta', 'miller', 'eleanora', 'eleanore', 'rusty', 'francesca', 'melvin', 'lucious', 'joell', 'roddy', 'admiral', 'noreta', 'dorr', 'avery', 'herb', 'eunice', 'jasmine', 'camren', 'dora', 'averi', 'aleen', 'karis', 'lashawn', 'karim', 'karin', 'karie', 'zakary', 'golden', 'armstead', 'dorthy', 'lynne', 'dortha', 'siddie', 'doretta', 'keara', 'nicholaus', 'vanesa', 'owen', 'leesa', 'louetta', 'ardath', 'makenzie', 'janene', 'addyson', 'maximilian', 'burnett', 'matilde', 'matilda', 'melony', 'theodosia', 'julissa', 'charlton', 'terance', 'kraig', 'cielo', 'damarcus', 'dimple', 'margueritta', 'archibald', 'amiya', 'granville', 'tatsuo', 'ronnie', 'cadence', 'hoy', 'barbra', 'flossie', 'destiney', 'festus', 'alline', 'destinee', 'carolynn', 'glenna']\n"
     ]
    }
   ],
   "source": [
    "names = set()\n",
    "with open(babyname_fn,\"r\") as f:\n",
    "    for line in f:\n",
    "        tokens = line.split(\",\")\n",
    "        name = tokens[1][1:-1]\n",
    "        names.add(name.lower())\n",
    "print list(names)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_dictionary():\n",
    "    extras = [\"lol\",\"rofl\",\"omg\",\"flickr\",\"facebook\",\"tumblr\",\"instagram\",\"myspace\",\"lyft\",\"airbnb\",\"com\",\"org\",\"pdf\",\n",
    "              \"edu\",\"htm\",\"html\",\"eg\",\"nb\",\"sketchup\",\"uber\",\"gmail\",\"http\",\"www\"] + list(names)\n",
    "    d = enchant.Dict(\"en_US\")\n",
    "    for word in extras:\n",
    "        d.add(word)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = create_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104446it [17:06, 96.51it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-af1b529c6f46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mlang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/uhellsc/anaconda/lib/python2.7/site-packages/langdetect/detector_factory.pyc\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_factory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/uhellsc/anaconda/lib/python2.7/site-packages/langdetect/detector.pyc\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mwhich\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mhighest\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         '''\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/uhellsc/anaconda/lib/python2.7/site-packages/langdetect/detector.pyc\u001b[0m in \u001b[0;36mget_probabilities\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlangprob\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sort_probability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlangprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/uhellsc/anaconda/lib/python2.7/site-packages/langdetect/detector.pyc\u001b[0m in \u001b[0;36m_detect_block\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_detect_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleaning_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mngrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mngrams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/uhellsc/anaconda/lib/python2.7/site-packages/langdetect/detector.pyc\u001b[0m in \u001b[0;36mcleaning_text\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mlatin_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_latin_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;34m'A'\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mch\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;34m'z'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                 \u001b[0mlatin_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mch\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\u0300'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0municode_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'Latin Extended Additional'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "top_ngrams = collections.Counter()\n",
    "def words(text): return re.findall(\"[a-z']+\", text.lower()) \n",
    "with open(text_fn,\"r\") as f:\n",
    "    for line in tqdm(f):\n",
    "        try:\n",
    "            lang = detect(line[:200])\n",
    "        except Exception:\n",
    "            continue\n",
    "        if lang != \"en\":\n",
    "            continue\n",
    "        for word in words(line):\n",
    "            if not d.check(word):\n",
    "                top_ngrams[word.lower()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52150\n",
      "5270\n"
     ]
    }
   ],
   "source": [
    "print len(top_ngrams)\n",
    "hits = 0\n",
    "for item,value in top_ngrams.iteritems():\n",
    "    if value > 5:\n",
    "        hits += 1\n",
    "print hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outfile = \"top.txt\"\n",
    "with open(outfile,\"w\") as f:\n",
    "    for item,value in top_ngrams.iteritems():\n",
    "        if value > 5:\n",
    "            f.write(item + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "with open(\"curated.txt\",\"r\") as f:\n",
    "    for line in tqdm(f):\n",
    "        d.add(line[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import re, collections\n",
    "\n",
    "def train(features):\n",
    "    model = collections.defaultdict(lambda: 1)\n",
    "    for f in tqdm(features):\n",
    "        if d.check(f):\n",
    "            model[f] += 1\n",
    "    return model\n",
    "\n",
    "NWORDS = train(words(file(small_text_fn).read()))\n",
    "\n",
    "alphabet = list(c for c in \"abcdefghijklmnopqrstuvwxyz'\") + [\"'t\"]\n",
    "\n",
    "def edits1(word):\n",
    "    s = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    deletes    = [a + b[1:] for a, b in s if b]\n",
    "    transposes = [a + b[1] + b[0] + b[2:] for a, b in s if len(b)>1]\n",
    "    replaces   = [a + c + b[1:] for a, b in s for c in alphabet if b]\n",
    "    inserts    = [a + c + b     for a, b in s for c in alphabet]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "#def known_edits2(word):\n",
    "#    return set(e2 for e1 in edits1(word) for e2 in edits1(e1) if e2 in NWORDS)\n",
    "\n",
    "def known(words): return set(w for w in words if w in NWORDS)\n",
    "\n",
    "def correct(word):\n",
    "    candidates = known([word]) or known(edits1(word)) or [word] #or known_edits2(word) or [word]\n",
    "    return max(candidates, key=NWORDS.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45505"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import codecs\n",
    "\n",
    "num_correct = 0\n",
    "num_incorrect = 0\n",
    "oov = 0\n",
    "incorrects = collections.Counter()\n",
    "with codecs.open(text_fn,\"r\",\"utf-8\") as f:\n",
    "    for line in tqdm(f):\n",
    "        try:\n",
    "            lang = detect(line)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if lang != \"en\":\n",
    "            continue\n",
    "        for word in words(line.lower()):\n",
    "            if word[-2:] == \"'s\":\n",
    "                word = word[:-2]\n",
    "            if not word:\n",
    "                continue\n",
    "            if word[0] == \"'\":\n",
    "                word = word[1:]\n",
    "            if not word:\n",
    "                continue\n",
    "            if word[-1] == \"'\":\n",
    "                word = word[:-1]\n",
    "            suggestions = [correct(word)]#d.suggest(word)\n",
    "            if suggestions and suggestions[0].lower() == word:\n",
    "                num_correct += 1\n",
    "            elif suggestions:\n",
    "                corrected = suggestions[0].lower() #correct(word)\n",
    "                num_incorrect += 1\n",
    "                incorrects[(word, corrected)] += 1\n",
    "            else:\n",
    "                oov += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51427385 259842 0\n"
     ]
    }
   ],
   "source": [
    "print num_correct, num_incorrect, oov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Edit = collections.namedtuple(\"Edit\",[\"word\",\"correct\",\"edit\"])\n",
    "def get_edit(word, correct):\n",
    "    if (word+\"s\") == correct:\n",
    "        return None\n",
    "    if word == (correct + \"s\"):\n",
    "        return None\n",
    "    s = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    deletes    = [Edit(word, a + b[1:], \"delete {}\".format(b[0])) for a, b in s if b]\n",
    "    transposes = [Edit(word, a + b[1] + b[0] + b[2:], \"transpose {}\".format(b[0:2])) for a, b in s if len(b)>1]\n",
    "    replaces   = [Edit(word, a + c + b[1:], \"replace {}->{}\".format(b[0],c)) for a, b in s for c in alphabet if b]\n",
    "    inserts    = [Edit(word, a + c + b, \"insert {}\".format(c)) for a, b in s for c in alphabet]\n",
    "    options = transposes + replaces + inserts + deletes\n",
    "    for entry in options:\n",
    "        if entry.correct == correct:\n",
    "            return entry.edit\n",
    "    return None\n",
    "\n",
    "def edit_factory(word, correct):\n",
    "    for index,(c,h) in enumerate(zip(word,correct)):\n",
    "        if c != h:\n",
    "            break\n",
    "    else:\n",
    "        index = len(word)\n",
    "    if len(correct) > len(word):\n",
    "        return lambda x,i : x[:i] + correct[index] + x[i:], index\n",
    "    if len(correct) < len(word):\n",
    "        return lambda x,i : x[:i] + x[i+1:], index\n",
    "    if index+1 >= len(word) or word[index+1] == correct[index+1]:\n",
    "        #mutation\n",
    "        return lambda x,i : x[:i] + correct[index] + x[i+1:], index\n",
    "    return lambda x,i : x[:i] + x[i+1] + x[i] + x[i+2:], index\n",
    "\n",
    "def get_edit_function(word, correct):\n",
    "    if (word+\"s\") == correct:\n",
    "        return None\n",
    "    if word == (correct + \"s\"):\n",
    "        return None\n",
    "    s = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    deletes    = [Edit(word, a + b[1:], \"delete {}\".format(b[0])) for a, b in s if b]\n",
    "    transposes = [Edit(word, a + b[1] + b[0] + b[2:], \"transpose {}\".format(b[0:2])) for a, b in s if len(b)>1]\n",
    "    replaces   = [Edit(word, a + c + b[1:], \"replace {}->{}\".format(b[0],c)) for a, b in s for c in alphabet if b]\n",
    "    inserts    = [Edit(word, a + c + b, \"insert {}\".format(c)) for a, b in s for c in alphabet]\n",
    "    options = transposes + replaces + inserts + deletes\n",
    "    for entry in options:\n",
    "        if entry.correct == correct:\n",
    "            return entry.edit\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "hits = collections.Counter()\n",
    "context = collections.defaultdict(list)\n",
    "for (word,_),weight in tqdm(incorrects.iteritems()):\n",
    "    target = correct(word)\n",
    "    if word != target:\n",
    "        edit = get_edit(word, target)\n",
    "        if edit is not None:\n",
    "            hits[edit] += weight\n",
    "            context[edit].append((word, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for entry in hits.most_common():\n",
    "#    print entry, context[entry[0]][:10]\n",
    "#    print \"---\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transposes = collections.Counter()\n",
    "replacements = collections.Counter()\n",
    "for hit, weight in hits.iteritems():\n",
    "    if \"transpose\" in hit:\n",
    "        chars = hit[-2:]\n",
    "        transposes[chars] += weight\n",
    "    elif \"replace\" in hit:\n",
    "        chars = hit[-4] + hit[-1]\n",
    "        replacements[chars] += weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#http://jayd.sauce.do/07/04/python-keyboard-heatmapper\n",
    "from PIL import Image\n",
    "key_location = {\"Escape\": (13, 10, 0), \"F1\": (78, 10, 0), \"F2\": (116, 10, 0), \"F3\": (154, 10, 0), \"F4\": (193, 10, 0), \"F5\": (253, 10, 0), \"F6\": (291, 10, 0), \"F7\": (329, 10, 0), \"F8\": (367, 10, 0), \"F9\": (428, 10, 0), \"F10\": (466, 10, 0), \"F11\": (504, 10, 0), \"F12\": (542, 10, 0), \"Snapshot\": (601, 10, 0), \"Scroll`\": (639, 10, 0), \"Pause\": (677, 10, 0), \"Oem_3\": (13, 82, 0), \"1\": (52, 83, 0), \"2\": (89, 82, 0), \"3\": (127, 82, 0), \"4\": (165, 82, 0), \"5\": (203, 82, 0), \"6\": (242, 82, 0), \"7\": (280, 82, 0), \"8\": (318, 82, 0), \"9\": (356, 82, 0), \"0\": (394, 82, 0), \"Oem_Minus\": (432, 82, 0), \"Oem_Plus\": (470, 82, 0), \"Back\": (508, 82, 1), \"Insert\": (603, 82, 0), \"Home\": (641, 82, 0), \"Prior\": (679, 82, 0), \"NumLock\": (738, 82, 0), \"Divide-\": (776, 82, 0), \"Multiply*\": (814, 82, 0), \"Subtract\": (852, 82, 0), \"Tab\": (13, 122, 2), \"Q\": (69, 122, 0), \"W\": (107, 122, 0), \"E\": (146, 122, 0), \"R\": (184, 122, 0), \"T\": (222, 122, 0), \"Y\": (260, 122, 0), \"U\": (297, 122, 0), \"I\": (336, 122, 0), \"O\": (374, 122, 0), \"P\": (412, 122, 0), \"Oem_4\": (449, 122, 0), \"Oem_6\": (487, 122, 0), \"Oem_5\": (526, 122, 3), \"Delete\": (602, 122, 0), \"End\": (640, 122, 0), \"Next\": (678, 122, 0), \"Numpad7\": (737, 122, 0), \"Numpad8\": (775, 122, 0), \"Numpad9\": (813, 122, 0), \"Add\": (852, 122, 4), \"Capital\": (13, 161, 5), \"A\": (79, 161, 0), \"S\": (117, 161, 0), \"D\": (156, 161, 0), \"F\": (194, 161, 0), \"G\": (232, 161, 0), \"H\": (270, 161, 0), \"J\": (308, 161, 0), \"K\": (346, 161, 0), \"L\": (384, 161, 0), \"Oem_1\": (422, 161, 0), \"Oem_7\": (461, 161, 0), \"Return\": (499, 161, 6), \"Numpad4\": (737, 161, 0), \"Numpad5\": (776, 161, 0), \"Numpad6\": (814, 161, 0), \"Lshift\": (13, 200, 7), \"Z\": (106, 200, 0), \"X\": (145, 200, 0), \"C\": (183, 200, 0), \"V\": (222, 200, 0), \"B\": (260, 200, 0), \"N\": (298, 200, 0), \"M\": (336, 200, 0), \"Oem_Comma\": (374, 200, 0), \"Oem_Period\": (413, 200, 0), \"Oem_2\": (451, 200, 0), \"Rshift\": (489, 200, 8), \"Up\": (641, 200, 0), \"Numpad1\": (738, 201, 0), \"Numpad2\": (775, 201, 0), \"Numpad3\": (814, 201, 0), \"NumpadReturn\": (851, 201, 9), \"Lcontrol\": (13, 240, 10), \"Lwin\": (69, 240, 11), \"Lmenu\": (119, 240, 11), \"Space\": (169, 240, 12), \"Rmenu\": (377, 240, 11), \"Rwin\": (427, 240, 11), \"Apps\": (476, 240, 11), \"Rcontrol\": (525, 240, 10), \"Left\": (603, 240, 0), \"Down\": (641, 240, 0), \"Right\": (679, 240, 0), \"Numpad0\": (738, 240, 13), \"Decimal\": (814, 240, 0)}\n",
    "img_w = 31\n",
    "img_h = 33\n",
    "def build_heatmap(hitmap, target):\n",
    "    biggest = float(max(v for k, v in hitmap.iteritems()))\n",
    "\n",
    "    heatmap = Image.open(\"heat_gradient.png\")\n",
    "    im = Image.open(\"keyboard.png\")\n",
    "\n",
    "    for k, v in hitmap.iteritems():\n",
    "        if(k not in key_location):\n",
    "            continue\n",
    "\n",
    "        heatbox = ((int((v/biggest)*500)-1), 0, int((v/biggest)*500)+1, 1)\n",
    "        heatRegion = heatmap.crop(heatbox)\n",
    "\n",
    "        heatColorInfo = heatRegion.getcolors()[0][1]\n",
    "\n",
    "        newImg = Image.new('RGB', (img_w, img_h), heatColorInfo)\n",
    "\n",
    "        box = (key_location[k][0], key_location[k][1], key_location[k][0]+img_w, key_location[k][1]+img_h)\n",
    "        region = im.crop(box)\n",
    "        region = Image.blend(region, newImg, .5)\n",
    "\n",
    "        im.paste(region, box)\n",
    "    \n",
    "    newImg = Image.new('RGB', (img_w, img_h), (0,0,0))\n",
    "\n",
    "    box = (key_location[target][0], key_location[target][1], key_location[target][0]+img_w, key_location[target][1]+img_h)\n",
    "    region = im.crop(box)\n",
    "    region = Image.blend(region, newImg, .5)\n",
    "\n",
    "    im.paste(region, box)\n",
    "\n",
    "    im.save('keyboard_heatmap.jpg')\n",
    "    im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_replacements_for(ch):\n",
    "    for_char = collections.Counter()\n",
    "    for chars,weight in replacements.iteritems():\n",
    "        if chars[0] == ch:\n",
    "            for_char[chars[1].upper()] += weight\n",
    "            \n",
    "    build_heatmap(for_char, ch.upper())\n",
    "    \n",
    "def show_transpositions_for(ch):\n",
    "    for_char = collections.Counter()\n",
    "    for chars,weight in transposes.iteritems():\n",
    "        if ch in chars:\n",
    "            for_char[chars[1].upper()] += weight\n",
    "            for_char[chars[0].upper()] += weight\n",
    "    print for_char\n",
    "    build_heatmap(for_char, ch.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_replacements_for(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print top_ngrams.most_common(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "trigram_to_function = collections.defaultdict(list)\n",
    "for (word,_),weight in tqdm(incorrects.iteritems()):\n",
    "    target = correct(word)\n",
    "    if word != target:\n",
    "        word,target = target,word #get inverses\n",
    "        edit, index = edit_factory(word, target)\n",
    "        padded = \"--\"+word\n",
    "        trigram = word[index-2:index+1]\n",
    "        trigram_to_function[trigram].append(edit)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def get_trigrams(word):\n",
    "    padded = \"--\"+word\n",
    "    trigrams = [padded[i:i+3] for i in xrange(len(padded)-2)]\n",
    "    return trigrams\n",
    "\n",
    "def inject_error_into_word(word, trigram_to_function):\n",
    "    trigrams = [tri for tri in get_trigrams(word)]\n",
    "    weights = numpy.array([len(trigram_to_function[tri]) for tri in trigrams])\n",
    "    if sum(weights) == 0:\n",
    "        return word\n",
    "    weights = weights / float(weights.sum())\n",
    "    index = numpy.random.choice(range(len(trigrams)), p=weights)\n",
    "    trigram = trigrams[index]\n",
    "    edit = numpy.random.choice(trigram_to_function[trigram])\n",
    "    return edit(word, index)\n",
    "    \n",
    "def inject_errors(text, trigram_to_function, p):\n",
    "    tokens = words(text)\n",
    "    modified = []\n",
    "    for word in tokens:\n",
    "        if numpy.random.random() < p:\n",
    "            modified.append(inject_error_into_word(word, trigram_to_function))\n",
    "        else:\n",
    "            modified.append(word)\n",
    "    return \" \".join(modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'foood'"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inject_error_into_word(\"food\", trigram_to_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'machine learning is closely related to computational statistics a discipline that aims at the design of algorithms for implementing statistical methods on computers it has strong ties to mathematical optimization which delivers methods theory and application domains to the field machine learning is employed in a range of computing tasks where designing and programming explicit algorithms is infeasible example applications include spam filtering optical character recognition ocr search engines and computer vision maxhine learning is somezimes conflated with data mining although that focuses more on exploreatory data analysis machine learning and pattern recognition cav be viewed as two facets of the same field'"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikitext = 'Machine learning is closely related to computational statistics; a discipline that aims at the design of algorithms for implementing statistical methods on computers. It has strong ties to mathematical optimization, which delivers methods, theory and application domains to the field. Machine learning is employed in a range of computing tasks where designing and programming explicit algorithms is infeasible. Example applications include spam filtering, optical character recognition (OCR), search engines and computer vision. Machine learning is sometimes conflated with data mining, although that focuses more on exploratory data analysis. Machine learning and pattern recognition \"can be viewed as two facets of the same field.\"'\n",
    "inject_errors(wikitext, trigram_to_function, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "with open(\"trigram_edits.pkl\", \"w\") as f:\n",
    "    dill.dump(trigram_to_function, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
